# -*- coding: utf-8 -*-
"""실습_6_CNN_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HONpDfTVkSBPmRcCn0HOjytEro3DWGyH

#CNN #1
"""

# Commented out IPython magic to ensure Python compatibility.
try:
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
import numpy as np

from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D
from tensorflow.keras import Model
from tensorflow.keras.models import Sequential

"""## ConvNet

> Convolutional Layer의 작동 방식을 알아보자!

### Conv1D
"""

# 6 timestep을 가진 128 길이의 벡터
# model_conv1.input_shape == (None, 6, 128)

input_ = tf.random.uniform((1, 6, 128))
conv1d = Conv1D(filters=32, kernel_size=3)

print(input_.shape)
print(conv1d(input_).shape)

# 6 timestep을 가진 128 길이의 벡터
# model_conv1.input_shape == (None, 6, 128)

model_conv1 = Sequential()
model_conv1.add(Conv1D(32, 3, input_shape=(6, 128)))

print(model_conv1.input_shape)

model_conv1.get_config()

"""###<font color='red'>잠깐 !</font>
> Output shape 계산식 : [(input_size-Kernel_size + padding*2)/stride] + 1 = output_size
"""

print(model_conv1.get_weights()) # same as model_conv1.variables
print(model_conv1.get_weights()[0].shape) # Weights
print(model_conv1.get_weights()[1].shape) # Bias

model_conv1.summary()

tf.keras.utils.plot_model(model_conv1, show_shapes=True)

conv1 = Conv1D(32, 3,input_shape=(6, 128))

input_ = tf.random.uniform((1, 6, 128))   # data 1건
input_100 = tf.random.uniform((100, 6, 128))   # data 100건

print(input_.shape)
print(conv1(input_).shape)

# batch size가 달라져도 가능
print(input_100.shape)
print(conv1(input_100).shape)

"""###Conv2D"""

model_conv2 = Sequential()
model_conv2.add(Conv2D(10, kernel_size=3, input_shape=(28, 28, 1)))    # MNIST data : 가로세로 28픽셀, 회색조 이미지
# kerner_size = (3,2) 이런식으로 가로/세로 다르게 할수있음.

print(model_conv2.input_shape)
print(model_conv2.get_weights()[0].shape) #conv kernel(filter) weight
print(model_conv2.get_weights()[1].shape) #conv kernel(filter) bias

"""###<font color='red'>잠깐 !</font>
Output shape은 뭐가 될까?
> Output shape 계산식 : [(input_size-Kernel_size + padding*2)/stride] + 1 = output_size
"""

model_conv2.summary()

tf.keras.utils.plot_model(model_conv2, show_shapes=True)

"""### <font color='red'>MISSION 1</font>
> input의 shape가 "[None, 32, 32, 1]"일 때
> output의 shape가 '[None, 15, 15, 10]'가 되도록 Conv Layer를 만들어보자.
> 이 때 사용해야 할 kernel size는 3 이다.

### <font color='red'>ANSWER 1</font>
"""

model_mission1 = Sequential()
#### ANSWER #### 
model_mission1.add(Conv2D(10, kernel_size=3, strides = (2, 2), input_shape=(32, 32, 1)))    # MNIST data : 가로세로 28픽셀, 회색조 이미지

#################
print(model_mission1.input_shape)
print(model_mission1.output_shape)

"""##MaxPool

> Maxpool의 활용을 이해해봅시다!
"""

model_mp1 = Sequential()
model_mp1.add(MaxPooling2D(pool_size=(3, 3), input_shape=(15, 15, 3)))

print(model_mp1.input_shape)
print(model_mp1.output_shape)

model_mp1 = Sequential()
model_mp1.add(MaxPooling2D(pool_size=(3, 3), input_shape=(30, 30, 3)))

print(model_mp1.input_shape)
print(model_mp1.output_shape)

"""##BatchNorm 2d"""

model_bn = Sequential()
model_bn.add(BatchNormalization(input_shape=(40, 40, 100)))
model_bn.summary()

"""##Build Network

# 실습 MISSION #9
### CIFAR10 데이터가 입력된다고 가정하고 네트워크를 구성해보자

CIFAR10 : 32 x 32 픽셀, RGB 컬러 이미지

* 3x3 필터를 64장 적용하는 convolution layer 1 층
* 2x2 pooling을 적용하는 MaxPool layer 1층
* 3x3 필터를 128장 적용하는 convolution layer 1 층 (단 입력과 동일한 size가 되도록 padding을 하자)
* 3x3 pooling을 적용하는 MaxPool layer 1층
* 4x4 필터를 100장 적용하는 convolution layer 1 층 
* 2x2 pooling을 적용하는 MaxPool layer 1층

* 모든 conv layer의 activation function으로 ReLU를 활용할 것

> output shape : (1, 1, 100)
"""

final_model1 = Sequential()
# final_model1.add(Conv2D(128, kernel_size=3, strides = (2, 2), input_shape=(32, 32, 1)))    # MNIST data : 가로세로 28픽셀, 회색조 이미지

# 여기에 mission 코드를 작성하세요
final_model1.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))
final_model1.add(MaxPooling2D(pool_size=(2, 2)))
final_model1.add(Conv2D(128, kernel_size=3, activation='relu', padding="same"))
final_model1.add(MaxPooling2D(pool_size=(3, 3)))
final_model1.add(Conv2D(100, kernel_size=4,activation='relu'))
final_model1.add(MaxPooling2D(pool_size=(2, 2)))


final_model1.summary()

"""# 실습 MISSION #10
### 위 네트워크의 모든 Conv에 BatchNormalization 적용하기

* 적용 순서는 CBAM (Conv-BatchNorm-Activation-MaxPool)
* activation function으로는 ReLU를 이용한다

> output shape : (1, 1, 100)
"""

# CIFAR10 : 32 x 32 픽셀, RGB 컬러 이미지
from tensorflow.keras.activations import relu

final_model1 = Sequential()

# 여기에 mission 코드를 작성하세요
final_model1.add(Conv2D(64, kernel_size=3, input_shape=(32, 32, 3)))    # MNIST data : 가로세로 28픽셀, 회색조 이미지
final_model1.add(BatchNormalization())
final_model1.add(Activation(activation='relu'))
final_model1.add(MaxPooling2D(pool_size=(2, 2)))
final_model1.add(Conv2D(128, kernel_size=3, padding="same"))    # MNIST data : 가로세로 28픽셀, 회색조 이미지
final_model1.add(BatchNormalization())
final_model1.add(Activation(activation='relu'))
final_model1.add(MaxPooling2D(pool_size=(3, 3)))
final_model1.add(Conv2D(100, kernel_size=4))    # MNIST data : 가로세로 28픽셀, 회색조 이미지
final_model1.add(BatchNormalization())
final_model1.add(Activation(activation='relu'))
final_model1.add(MaxPooling2D(pool_size=(2, 2)))


final_model1.summary()