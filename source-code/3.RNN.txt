//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
1. 데이터



from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

1. oov 추가
tokenizer = Tokenizer(num_words = 100, oov_token="<OOV>")

2. string 타입 문장 넣어줌
tokenizer.fit_on_texts(sentences)

3. 인덱스 매핑. 사전 만들기.
word_index = tokenizer.word_index

4. sequence 만듦. 정수화
sequences = tokenizer.texts_to_sequences(sentences)

5. 패딩 넣어줌.
padded = pad_sequences(sequences, maxlen=5)



//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
2. 모델





//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
3. 학습





//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////
4. 결과 시각화





tdc
3-1-2 
padded 만들기. 기본
3-1-3 
padded 만들기. json 불러오고 dictionary 파싱
3-1-exercise 
padded 만들기. csv 불러오고 stop words 조건하에 파싱. label 값도 sequence

3-2-1 
imdb_reviews
3-2-2 
is_sarcastic
3-2-exercise 
bbc-text.csv. stop words 적용. 데이터 나누는거에 힘줌. 학습 후 plot. reverse vecs.tsv, meta.tsv 다 나옴.

3-3
모델 레이어 여러가지 소개하면서 성능 높이기

3-4-2
irish-lyrics-eof.txt
아 진짜 뭐래는거야

nlp_exercise
nlp_shapespeare
다 똑같은데 받아오는 데이터 형식이 달라서 데이터 전처리 부분만 다른듯.
하 겁나 귀찮네 이거도 다 보고 가야되나

